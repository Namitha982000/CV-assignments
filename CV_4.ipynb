{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c47711bf-25fe-4dbe-bc42-4192559c2b5e",
   "metadata": {},
   "source": [
    "# Assignment 4"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf7f5c38-5a8d-45d9-a188-7d68d7b44060",
   "metadata": {},
   "source": [
    "#### 1. What is the concept of cyclical momentum?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cb4a100-32de-4b4f-8c97-4c4a91022a45",
   "metadata": {},
   "source": [
    "The term \"cyclical momentum\" refers to the change in momentum values that occurs as a neural network is being trained. Stochastic gradient descent (SGD) and other optimisation algorithms use the momentum technique to hasten convergence and increase learning process stability.\n",
    "\n",
    "The weight that is traditionally given to the prior update while computing the current update of the model parameters is determined by a parameter called momentum. Even when the gradient shifts or fluctuates, it assists the optimisation algorithm to keep going in the prior path. The momentum term functions as a moving average of the gradients and enables the algorithm to move beyond flat areas or tiny local optima by gaining momentum in predictable directions.\n",
    "\n",
    "In the concept of cyclical momentum, the momentum parameter is varied cyclically during training. Instead of using a fixed momentum value throughout the training process, the momentum is gradually increased and decreased within a specific range or cycle. This cyclic variation allows the optimization algorithm to explore different update directions and adapt the momentum based on the current state of the training process.\n",
    "\n",
    "The idea behind cyclical momentum is to introduce additional exploration and adaptability to the optimization process. By varying the momentum, the algorithm can escape from poor local minima, explore different regions of the parameter space, and potentially find better solutions. This cyclic variation of momentum helps to balance exploration and exploitation, allowing the optimization process to explore wider regions during some cycles and exploit promising regions during others.\n",
    "\n",
    "Cyclical momentum is often used in conjunction with other techniques, such as learning rate schedules or cyclical learning rates, to further enhance the optimization process and improve the performance of the neural network. By combining cyclical momentum with other cyclical techniques, the training process can become more robust, adaptable, and capable of discovering better solutions."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c087a1c-998e-4523-9f4f-735c472a5a4c",
   "metadata": {},
   "source": [
    "#### 2. What callback keeps track of hyperparameter values (along with other data) during training?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95b258dd-9b73-46e1-83d7-c347c7c45c16",
   "metadata": {},
   "source": [
    "The callback that records hyperparameter values (together with other data) during training is typically referred to as a \"callback logger\" or \"metrics logger\" in the context of deep learning frameworks like PyTorch or TensorFlow. Throughout the training process, this callback is in charge of logging and recording a variety of data and metrics, including hyperparameter values, loss values, accuracy, validation metrics, and other pertinent statistics.\n",
    "\n",
    "The callback logger typically operates by intercepting specific events or stages during training, such as the completion of each training batch, the end of each epoch, or the completion of the entire training process. It collects the desired data at these points and stores them for later analysis or visualization.\n",
    "\n",
    "The specific implementation and functionality of the callback logger may vary depending on the deep learning framework or library being used. In PyTorch, for example, the `torch.utils.tensorboard.SummaryWriter` class can be used as a callback logger to log various metrics and hyperparameters during training. It can write the logged information to TensorBoard-compatible files, which can then be visualized using the TensorBoard tool.\n",
    "\n",
    "Different callback loggers or metrics recording systems could be offered by different deep learning frameworks and packages. These recorders are useful for tracking the training process's development, evaluating the model's performance, and making defensible judgements based on the logged data, such as modifying hyperparameters, spotting overfitting, or contrasting various training sessions."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c118f03b-7852-409e-a0fe-207c9512eb6c",
   "metadata": {},
   "source": [
    "#### 3. In the color dim plot, what does one column of pixels represent?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f3f44a2-0aad-4580-b394-493d6dff32eb",
   "metadata": {},
   "source": [
    "One column of pixels often indicates the fluctuation of a particular dimension or feature across the data samples in the context of a colour dim plot, where the data is represented as an image.\n",
    "\n",
    "Each pixel in a colour dim plot refers to a distinct data sample, and the colour of the pixel denotes the value of a certain feature or dimension of that sample. The plot is often laid out so that the rows represent individual data samples and the columns indicate various attributes or dimensions..\n",
    "\n",
    "For example, consider a color dim plot where each row represents an image and each column represents a specific color channel (e.g., red, green, blue). In this case, one column of pixels in the plot would represent the variation of the pixel values in that specific color channel across the images. Each pixel's color in that column would indicate the intensity or magnitude of the corresponding color channel for a particular image.\n",
    "\n",
    "It is possible to examine the distribution, trends, or correlations of the related feature or dimension across the data samples by looking at the colour variations within a column. This can shed light on the structure of the data, show where samples differ or overlap, or help pinpoint key characteristics for more investigation or modelling.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c945c4e9-2f9c-4179-98df-49842f434e27",
   "metadata": {},
   "source": [
    "#### 4. In color dim, what does \"poor teaching\" look like? What is the reason for this?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e6ee93e-8727-42b8-a721-f3b08916c033",
   "metadata": {},
   "source": [
    "\"Poor teaching\" in the context of a colour dim plot refers to the case where the visualisation fails to successfully communicate significant information or insights about the data. This indicates that the plot doesn't offer obvious and understandable patterns or correlations between the dimensions or features being visualised..\n",
    "\n",
    "There can be several reasons for a color dim plot to exhibit poor teaching:\n",
    "\n",
    "1. **Irrelevant or Uninformative Dimensions**: If the dimensions or features being visualized in the color dim plot are irrelevant or uninformative for understanding the data, the plot may not reveal any meaningful patterns or insights. In such cases, the plot may appear random or lack structure, making it difficult to draw meaningful conclusions.\n",
    "\n",
    "2. **High Dimensionality**: Color dim plots can become less effective when visualizing high-dimensional data. As the number of dimensions or features increases, it becomes challenging to represent them all in a single plot. The plot may become crowded or too complex to interpret, making it difficult to extract useful information.\n",
    "\n",
    "3. **Lack of Contrast or Discrimination**: If the color scheme or mapping used in the color dim plot does not provide sufficient contrast or discrimination between different values or ranges of the dimensions, it can make it challenging to distinguish patterns or identify relationships. The lack of clarity in the visual representation can lead to poor teaching.\n",
    "\n",
    "4. **Data Variability**: In some cases, the data being visualized may exhibit low variability or lack distinctive patterns across the dimensions. This can result in a color dim plot that appears homogeneous or indistinguishable, providing limited insights into the data.\n",
    "\n",
    "5. **Non-linear Relationships**: If the relationships between dimensions or features in the data are non-linear or complex, a simple color dim plot may not effectively capture these relationships. Linear or monotonic visualizations may fail to reveal the underlying structure of the data, leading to poor teaching."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "119a6e11-4b79-4b60-825c-cfdcf9a4b891",
   "metadata": {},
   "source": [
    "#### 5. Does a batch normalization layer have any trainable parameters?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ddde821-95dd-4d38-808d-992f0067573d",
   "metadata": {},
   "source": [
    "Yes, The parameters of a batch normalisation layer are trainable. During training for batch normalisation, the layer picks up and changes two different kinds of parameters:\n",
    "\n",
    "1. **Scale Parameter (γ)**: This parameter is used to scale the normalized activations. It allows the batch normalization layer to control the magnitude of the normalized activations. The scale parameter is learned and updated during training, which means it is a trainable parameter.\n",
    "\n",
    "2. **Shift Parameter (β)**: This parameter is used to shift the normalized activations. It allows the batch normalization layer to control the bias or offset of the normalized activations. Similar to the scale parameter, the shift parameter is also learned and updated during training, making it a trainable parameter.\n",
    "\n",
    "These trainable parameters, the scale parameter (γ) and the shift parameter (β), provide flexibility to the batch normalization layer to adapt to different distributions of the input data and optimize the performance of the neural network. By adjusting the scale and shift of the normalized activations, batch normalization helps to improve the gradient flow, reduce internal covariate shift, and stabilize the training process.\n",
    "\n",
    "It's important to note that batch normalization also utilizes two additional sets of parameters:\n",
    "\n",
    "1. **Running Mean**: This parameter keeps track of the moving average of the mean value of the input batch during training. It is used during inference to normalize the input based on the estimated population mean.\n",
    "\n",
    "2. **Running Variance**: This parameter keeps track of the moving average of the variance of the input batch during training. It is used during inference to normalize the input based on the estimated population variance."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a0df43a-185a-424b-abc4-3349cac57b15",
   "metadata": {},
   "source": [
    "#### 6. In batch normalization during preparation, what statistics are used to normalize? What about during the validation process?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74e8156d-eb11-44c5-a20e-b28085e77658",
   "metadata": {},
   "source": [
    "The statistics used to normalise the input batch are calculated depending on the current mini-batch being processed during the batch normalisation training phase. Particularly, the mean and the variance of two statistics are computed.\n",
    "\n",
    "The average of the input batch along each channel or feature dimension is used to calculate the mean. It displays the average value of the batch's activations.\n",
    "\n",
    "The input batch variance along each channel or feature dimension is used to calculate variance. It represents the distribution or dispersion of the batch's activations.\n",
    "\n",
    "Once the mean and variance are computed for the current mini-batch, the input batch is normalized using these statistics. The normalization process involves subtracting the mean from each activation and then dividing by the square root of the variance. This normalization step ensures that the activations have a mean of zero and a variance of one, helping to stabilize and normalize the input distribution.\n",
    "\n",
    "During the validation process or inference, batch normalization behaves slightly differently. Instead of using the statistics calculated from the current mini-batch, the running mean and running variance are used for normalization. These running statistics are computed as moving averages during the training process.\n",
    "\n",
    "The running mean represents the moving average of the mean values calculated across all the mini-batches seen during training. It provides an estimation of the population mean.\n",
    "\n",
    "Similarly, the running variance represents the moving average of the variance values calculated across all the mini-batches seen during training. It provides an estimation of the population variance.\n",
    "\n",
    "These running mean and variance values are utilised to normalise the input data during validation or inference. As a result, the statistics utilised for training are consistent, and the normalisation behaviour that was learned during training is preserved.\n",
    "\n",
    "Batch normalisation enables the model to generalise well to unseen data and guarantees consistent normalisation behaviour throughout various stages of the training process by utilising the running mean and variance for normalisation during validation."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "921b80ee-c0b1-4078-9110-ba42f173bfbd",
   "metadata": {},
   "source": [
    "#### 7. Why do batch normalization layers help models generalize better?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea00dd48-741d-437e-b09c-067bc373e6e5",
   "metadata": {},
   "source": [
    "Batch normalization layers help models generalize better for several reasons:\n",
    "\n",
    "1. **Normalization of Activations**: Batch normalization normalizes the activations within each mini-batch by subtracting the mini-batch mean and dividing by the mini-batch standard deviation. This normalization process helps to stabilize the distribution of activations, making them more consistent and reducing the internal covariate shift. By ensuring that the activations have similar statistical properties across mini-batches, batch normalization reduces the sensitivity of the model to the scale and distribution of the input data. This, in turn, helps the model generalize better to unseen examples.\n",
    "\n",
    "2. **Regularization Effect**: Batch normalization introduces a regularization effect by adding noise to the hidden units through the normalization process. The noise injected into the activations during training acts as a form of regularization, which can prevent overfitting. By adding noise to the activations, batch normalization reduces the reliance of the model on specific instances or patterns within the mini-batches, forcing it to learn more robust and generalized representations.\n",
    "\n",
    "3. **Stabilized Gradient Flow**: Batch normalization helps to alleviate the vanishing gradient problem and ensures a more stable gradient flow during training. By normalizing the activations and reducing the internal covariate shift, batch normalization keeps the gradients within a reasonable range, preventing them from becoming too small or too large. This facilitates the backpropagation of gradients through deep networks, enabling more effective and efficient training. The stabilized gradient flow allows the model to converge faster and generalize better to new examples.\n",
    "\n",
    "4. **Reduction of Dependency on Initialization**: Batch normalization reduces the dependence of the model on the specific initialization of the network parameters. By normalizing the activations, batch normalization makes the model less sensitive to the choice of initialization values. This reduces the burden of finding the optimal initialization scheme and makes the training process more robust and reliable."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e5c0da6-1553-4b1a-ae38-973cef4b02df",
   "metadata": {},
   "source": [
    "#### 8.Explain between MAX POOLING and AVERAGE POOLING is number eight."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec675e8b-457d-4456-bb04-5bc834685703",
   "metadata": {},
   "source": [
    "1. **Max Pooling**: In max pooling, each pooling region is divided into non-overlapping patches, typically of size (e.g., 2x2 or 3x3). Within each patch, the maximum value is selected as the representative value. This means that only the highest activation within each patch is preserved, discarding the rest. Max pooling emphasizes the most prominent features or activations within each patch and retains the strongest signal, disregarding the lower activations. It is effective in capturing the most salient features and providing translation invariance, making it particularly useful for tasks where detecting presence or location of specific features is important.\n",
    "\n",
    "2. **Average Pooling**: In average pooling, each pooling region is divided into non-overlapping patches, similar to max pooling. However, instead of selecting the maximum value, average pooling calculates the average (mean) value within each patch. This means that all the activations within each patch contribute equally to the pooled value. Average pooling provides a more smoothed representation of the input and helps to reduce noise or small variations. It can be useful in scenarios where the absolute presence or precise location of specific features is less important, and a more generalized representation is desired.\n",
    "\n",
    "By lowering the spatial dimensions of the feature maps, both max pooling and average pooling reduce the number of parameters and computational complexity in following layers. By condensing the data in each pooling zone, they also introduce a certain amount of translation invariance.\n",
    "\n",
    "Max pooling or average pooling should be chosen depending on the particulars of the problem at hand and the desired qualities of the final representation. Because it preserves the strongest activations and offers more robustness against minute translations, max pooling is frequently chosen when recognising certain characteristics or patterns. On the other hand, average pooling can be helpful for tasks like picture classification or gathering comprehensive spatial information when a more generalised representation or smoothing effect is sought."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d058f8f-a108-471a-8aa5-e2530c5d69c2",
   "metadata": {},
   "source": [
    "#### 9. What is the purpose of the POOLING LAYER?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f21d955-072b-44de-96c5-c8d893ad0a3f",
   "metadata": {},
   "source": [
    "1. **Dimensionality Reduction**: The pooling layer reduces the spatial dimensions (width and height) of the feature maps. This downsampling helps to decrease the computational complexity of the network and reduce the number of parameters. By reducing the spatial resolution, the pooling layer enables subsequent layers to focus on more high-level and abstract features.\n",
    "\n",
    "2. **Translation Invariance**: Pooling layers introduce a degree of translation invariance by summarizing the information within local regions. By aggregating the features within each pooling region, the pooling layer can capture the most important information and discard less relevant or redundant details. This translation invariance property allows the network to recognize patterns or features regardless of their exact location within the input.\n",
    "\n",
    "3. **Feature Extraction**: The pooling layer acts as a feature extractor by preserving the most prominent features. By selecting the most representative value within each pooling region (e.g., maximum value in max pooling), the pooling layer retains the strongest activations and discards weaker ones. This helps to emphasize important features and reduce the influence of noisy or less significant activations.\n",
    "\n",
    "4. **Spatial Hierarchies**: Pooling layers create spatial hierarchies by gradually reducing the spatial dimensions. As the pooling layers are stacked, the receptive fields of the neurons in higher layers become larger, capturing information from larger regions of the input. This hierarchical structure allows the network to learn increasingly complex and abstract features at higher layers."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63235502-14a8-45e2-abd5-3dee1ca89cfb",
   "metadata": {},
   "source": [
    "#### 10. Why do we end up with Completely CONNECTED LAYERS?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca4b88ce-01fb-42aa-b179-9716ae33fdad",
   "metadata": {},
   "source": [
    "1. **Global Information Aggregation**: Convolutional layers in a CNN extract local features through convolutional operations with small receptive fields. However, these local features may not capture the global context or relationships between different parts of the input. Fully connected layers, on the other hand, provide a way to aggregate information from the entire input space by connecting each neuron to every neuron in the previous layer. This allows the network to capture global patterns and dependencies, making it suitable for tasks that require holistic understanding or higher-level reasoning.\n",
    "\n",
    "2. **Non-Local Relationships**: Fully connected layers enable the model to learn non-local relationships between different features. While convolutional layers are effective at learning local patterns and spatial hierarchies, they may not capture long-range dependencies or relationships that extend beyond the receptive field of the convolutional filters. Fully connected layers allow for more flexible connections between neurons, facilitating the learning of complex non-local relationships in the data.\n",
    "\n",
    "3. **Feature Combination**: Fully connected layers provide a mechanism for combining features learned by earlier layers. The convolutional layers in a CNN extract low-level features in the earlier layers and progressively learn more abstract and higher-level features in subsequent layers. Fully connected layers receive these learned features as inputs and can combine them to form more complex representations. This allows the model to learn task-specific combinations of features that are relevant for the given problem.\n",
    "\n",
    "4. **Decision Making**: Fully connected layers are often used as the final layers of a CNN to make predictions or decisions based on the learned features. These layers typically have a fixed number of neurons corresponding to the desired output classes or regression targets. Each neuron in the fully connected layers represents a specific class or target, and the activations of these neurons indicate the model's confidence or prediction for each class or target."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "188b2620-fbe2-4559-892c-b6d58ed30b1b",
   "metadata": {},
   "source": [
    "#### 11. What do you mean by PARAMETERS?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be08d559-0e43-41be-931d-c2a65b9e6728",
   "metadata": {},
   "source": [
    "\"Parameters\" in the context of neural networks refer to the learnable variables that specify how the model behaves and how it is constructed. The neural network learns these parameters from the training data in order to execute a given task or generate predictions. As they control how the input data is translated and processed within the network, parameters are a crucial part of the model.\n",
    "\n",
    "The two main types of parameters in a neural network are:\n",
    "\n",
    "1. **Weights**: Weights are the coefficients that multiply the input values at each layer. They represent the strength of the connections between neurons or units in different layers of the network. Each connection between two neurons has an associated weight that determines the contribution of the input value to the activation of the receiving neuron. The weights control the influence of the input on the output and are adjusted during the training process to optimize the performance of the network.\n",
    "\n",
    "2. **Biases**: Biases are additional parameters in a neural network that represent the intercept or offset term. A bias term is added to the weighted sum of inputs at each neuron in the network. It allows the network to learn an offset or bias in the predictions, providing flexibility in modeling different patterns and relationships. Biases help the network capture non-zero mean patterns in the data and adjust the decision boundaries of the model.\n",
    "\n",
    "These parameters are initially initialised with random values, and via training, the network learns the ideal values. A loss function that measures the difference between expected outputs and actual targets is used to assess the network's performance during training. Following that, optimisation techniques like gradient descent are used to update the weights and biases in order to reduce the loss function and enhance the model's performance.\n",
    "\n",
    "The architecture and configuration of the network, including the number of layers, the number of neurons in each layer, and any extra design decisions, affect the number of parameters in a neural network. Finding the ideal values for these parameters during the learning process will allow the network to accurately represent underlying patterns and make predictions on brand-new, unforeseen data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4f22253-0f35-4025-a986-c4a80ba3ef5c",
   "metadata": {},
   "source": [
    "#### 12. What formulas are used to measure these PARAMETERS?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a46f0364-43db-4b24-bb27-fe253297a583",
   "metadata": {},
   "source": [
    "1. **Number of Weights (W)**: The number of weights in a neural network can be calculated by summing up the total number of weights in each layer. For a fully connected layer, the number of weights is determined by the size of the input and output layers. If the input layer has dimension M and the output layer has dimension N, the number of weights in that layer would be M * N. For convolutional layers, the number of weights depends on the size of the convolutional filters and the number of input and output channels.\n",
    "\n",
    "2. **Number of Biases (B)**: The number of biases in a neural network is equal to the number of neurons or units in each layer, excluding the input layer. Each neuron (except in the input layer) has its own bias term, so the number of biases in a layer is the same as the number of neurons in that layer.\n",
    "\n",
    "3. **Total Number of Parameters**: The total number of parameters in a neural network is the sum of the number of weights and the number of biases. It represents the overall complexity of the model and the amount of memory required to store and process the parameters during inference.\n",
    "\n",
    "4. **Total Memory Usage**: The memory usage of a neural network is related to the total number of parameters. Each parameter typically requires a certain number of bits or bytes to be stored. The memory usage can be computed by multiplying the total number of parameters by the number of bits/bytes required to store each parameter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5779f193-3fb5-4be7-89b0-4d698d747c42",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
